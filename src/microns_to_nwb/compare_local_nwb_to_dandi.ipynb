{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a1785e-8135-4b25-979a-78bf101de46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting microns@db.datajoint.com:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not create the ~log table\n",
      "Could not access table `microns_phase3_nda`.`~log`\n"
     ]
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "dj.config[\"database.host\"] = \"db.datajoint.com\"\n",
    "dj.config[\"database.user\"] = \"microns\"\n",
    "dj.config[\"database.password\"] = \"microns2023\"\n",
    "nda = dj.create_virtual_module('nda', 'microns_phase3_nda')\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "# from h5py import File\n",
    "# from fsspec.implementations.cached import CachingFileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f256fdac-d64c-4ed3-ac9d-620e0561d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session': 4, 'scan_idx': 9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source data file paths\n",
    "scan_keys = list(nda.Scan.proj())\n",
    "k = scan_keys[1]\n",
    "display(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aac5d3-f389-4923-8e53-763a8b736355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pynwb/image.py:106: UserWarning: ImageSeries 'Video: stimulus_17797_4_9_v4': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get local nwb file (newly generated with updated code)\n",
    "ophys_file_version = 2\n",
    "local_parent_path = \"/mnt/at-export01/17797-export/DANDI_NWB/\"\n",
    "local_file_stem = f\"functional_scan_17797_{k['session']}_{k['scan_idx']}_v{ophys_file_version}\"\n",
    "local_file_path = local_parent_path + local_file_stem + '/' + local_file_stem + \".nwb\"\n",
    "local_file = h5py.File(local_file_path,mode='r')\n",
    "local_file_io = NWBHDF5IO(file=local_file,load_namespaces=True)\n",
    "local_nwbfile = local_file_io.read()\n",
    "\n",
    "# get dandi local nwb file (previously generated by catalyst, downlaoded from dandiarchive)\n",
    "dandi_parent_path = '/mnt/at-export01/17797-export/DANDI_NWB/dandi_download_000402_2023_11_21/000402/sub-17797/'\n",
    "dandi_file_path = dandi_parent_path + f\"sub-17797_ses-{k['session']}-scan-{k['scan_idx']}_behavior+image+ophys.nwb\"\n",
    "dandi_file = h5py.File(dandi_file_path,mode='r')\n",
    "dandi_file_io = NWBHDF5IO(file=dandi_file)#,load_namespaces=True)\n",
    "dandi_nwbfile = dandi_file_io.read()\n",
    "\n",
    "# # get dandi streaming nwb file (not recommended since big data pulls are slow on runtime)\n",
    "# from dandi.dandiapi import DandiAPIClient\n",
    "# from fsspec import filesystem\n",
    "# dandiset_id = \"000402\"\n",
    "# # file_path = \"sub-17797/sub-17797_ses-9-scan-4_behavior+image+ophys.nwb\" # file size ~67GB\n",
    "\n",
    "# dandi_path = f\"sub-17797/sub-17797_ses-{k['session']}-scan-{k['scan_idx']}_behavior+image+ophys.nwb\"\n",
    "\n",
    "# # Get the location of the file on DANDI\n",
    "# with DandiAPIClient() as client:\n",
    "#     asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(dandi_path)\n",
    "#     s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "# # Create a virtual filesystem based on the http protocol and use caching to save accessed data to RAM.\n",
    "# fs = filesystem(\"http\")\n",
    "# dandi_file_path = fs.open(s3_url, \"rb\")\n",
    "# dandi_file = h5py.File(dandi_file_path, mode=\"r\")\n",
    "# # Open the file with NWBHDF5IO\n",
    "# dandi_file_io = NWBHDF5IO(file=dandi_file, load_namespaces=True)\n",
    "# dandi_nwbfile = dandi_file_io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10586808-5a81-4bff-9055-b569ffeefef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_nwb_files(file1_path, file2_path, verbose=False, excluded_attributes = set(['object_id']), excluded_datasets = set(['data','file_create_date','identifier','session_description'])):\n",
    "    def compare_arrays(arr1, arr2, n_samples = 5, path=\"/\"):\n",
    "        \"\"\"\n",
    "        Compares the first, last, and random n elements of two numpy arrays.\n",
    "        \"\"\"\n",
    "        indices_to_compare = sorted([0, len(arr1)-1] + list(np.random.choice(len(arr1), size=np.min((n_samples,len(arr1))), replace=False)))\n",
    "    \n",
    "        arr1_subset = arr1[indices_to_compare]\n",
    "        arr2_subset = arr2[indices_to_compare]\n",
    "\n",
    "        if arr1_subset.dtype == 'O' and arr2_subset.dtype == 'O':\n",
    "            if not np.array_equal(arr1_subset,arr2_subset):\n",
    "                print(f\"Difference in array '{path}' (subset):\")\n",
    "                print(f\"  Array 1: {arr1_subset}\")\n",
    "                print(f\"  Array 2: {arr2_subset}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No difference in array '{path}' (subset):\")\n",
    "        else:\n",
    "            if not np.array_equal(arr1_subset, arr2_subset,equal_nan=True):\n",
    "                print(f\"Difference in array '{path}' (subset):\")\n",
    "                print(f\"  Array 1: {arr1_subset}\")\n",
    "                print(f\"  Array 2: {arr2_subset}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No difference in array '{path}' (subset):\")\n",
    "    \n",
    "    def compare_datasets(dataset1, dataset2, path=\"/\"):\n",
    "        \"\"\"\n",
    "        Recursively compares datasets within nested structures.\n",
    "        \"\"\"\n",
    "        if isinstance(dataset1, h5py.Group) and isinstance(dataset2, h5py.Group):\n",
    "            # Compare group attributes (excluding 'object_id')\n",
    "            attrs1 = {key: dataset1.attrs[key] for key in dataset1.attrs if key not in excluded_attributes}\n",
    "            # attrs2 = {key: dataset2.attrs[key] for key in dataset2.attrs if key != 'object_id'}\n",
    "            attrs2 = {key: dataset2.attrs[key] for key in dataset2.attrs if key not in excluded_attributes}\n",
    "\n",
    "            key_match = attrs1.keys() == attrs2.keys()\n",
    "            non_reference_match = np.all([np.all(v1==v2) for v1,v2 in zip(attrs1.values(),attrs2.values()) \n",
    "                                          if not np.all([isinstance(v,h5py.h5r.Reference) for v in (v1,v2)])])\n",
    "            reference_match = np.all([file1[v1].name == file2[v2].name for v1,v2 in zip(attrs1.values(),attrs2.values()) \n",
    "                                      if np.all([isinstance(v,h5py.h5r.Reference) for v in (v1,v2)])])\n",
    "\n",
    "            if not (key_match and non_reference_match and reference_match):\n",
    "            # if attrs1 != attrs2:\n",
    "                print(f\"Difference in attributes in group '{path}'\")\n",
    "                print(f\"  attr 1: {attrs1}\")\n",
    "                print(f\"  attr 2: {attrs2}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No difference in attributes in group '{path}'\")\n",
    "\n",
    "            # Recursively compare datasets in the group\n",
    "            for key in dataset1.keys():\n",
    "                if key in dataset2:\n",
    "                    if key in excluded_datasets:\n",
    "                        print(f'skipping dataset {key}')\n",
    "                    else:\n",
    "                        compare_datasets(dataset1[key], dataset2[key], path + \"/\" + key)\n",
    "                else:\n",
    "                    print(f\"Dataset '{key}' is missing in '{path}' in second file\")\n",
    "            \n",
    "            for key in dataset2.keys():\n",
    "                if key not in dataset1:\n",
    "                    print(f\"Dataset '{key}' is missing in '{path}' in first file\")\n",
    "\n",
    "        elif isinstance(dataset1, h5py.Dataset) and isinstance(dataset2, h5py.Dataset):\n",
    "            # Compare dataset attributes (excluding 'object_id')\n",
    "            attrs1 = {key: dataset1.attrs[key] for key in dataset1.attrs if key != 'object_id'}\n",
    "            attrs2 = {key: dataset2.attrs[key] for key in dataset2.attrs if key != 'object_id'}\n",
    "\n",
    "            key_match = attrs1.keys() == attrs2.keys()\n",
    "            non_reference_match = np.all([np.all(v1==v2) for v1,v2 in zip(attrs1.values(),attrs2.values()) \n",
    "                                          if not np.all([isinstance(v,h5py.h5r.Reference) for v in (v1,v2)])])\n",
    "            reference_match = np.all([file1[v1].name == file2[v2].name for v1,v2 in zip(attrs1.values(),attrs2.values()) \n",
    "                                      if np.all([isinstance(v,h5py.h5r.Reference) for v in (v1,v2)])])\n",
    "\n",
    "            if not (key_match and non_reference_match and reference_match):\n",
    "            # if attrs1 != attrs2:\n",
    "                print(f\"Difference in attributes in dataset '{path}'\")\n",
    "                print(f\"  attr 1: {attrs1}\")\n",
    "                print(f\"  attr 2: {attrs2}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No difference in attributes in dataset '{path}'\")\n",
    "\n",
    "            # Compare dataset shapes\n",
    "            if dataset1.shape != dataset2.shape:\n",
    "                print(f\"Difference in shapes in dataset '{path}': {dataset1.shape} vs {dataset2.shape}\")\n",
    "                return\n",
    "\n",
    "            # Compare dataset values (including arrays)\n",
    "            if isinstance(dataset1[()], np.ndarray) and isinstance(dataset2[()], np.ndarray):# and len(dataset1[()])>2 and len(dataset2[()])>2:\n",
    "                compare_arrays(dataset1[()], dataset2[()], path=path)\n",
    "            elif not np.all((dataset1[()] == dataset2[()])):\n",
    "                if dataset1.dtype == 'O' and dataset2.dtype == 'O':\n",
    "                    print(f\"Difference in dataset '{path}':\")\n",
    "                    print(f\"  File 1: {dataset1[()]}\")\n",
    "                    print(f\"  File 2: {dataset2[()]}\")\n",
    "                elif not np.all((dataset1[()] == dataset2[()]) | (np.isnan(dataset1[()]) & np.isnan(dataset2[()]))):\n",
    "                    print(f\"Difference in dataset '{path}':\")\n",
    "                    print(f\"  File 1: {dataset1[()]}\")\n",
    "                    print(f\"  File 2: {dataset2[()]}\")\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"No difference in dataset '{path}':\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No difference in dataset '{path}':\")\n",
    "        else:\n",
    "            print(f\"unhandled type {type(dataset1)},{type(dataset2)}\")\n",
    "            \n",
    "\n",
    "    # Open the NWB files\n",
    "    with h5py.File(file1_path, 'r') as file1, h5py.File(file2_path, 'r') as file2:\n",
    "        # Compare the root groups\n",
    "        compare_datasets(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fdebf8-1ac6-462e-8782-0116b5f54070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in attributes in group '/'\n",
      "  attr 1: {'.specloc': <HDF5 object reference>, 'namespace': 'core', 'neurodata_type': 'NWBFile', 'nwb_version': '2.6.0'}\n",
      "  attr 2: {'.specloc': <HDF5 object reference>, 'namespace': 'core', 'neurodata_type': 'NWBFile', 'nwb_version': '2.5.0'}\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "Difference in shapes in dataset '//acquisition/Video: stimulus_17797_4_9_v4/timestamps': (334501,) vs (334509,)\n",
      "skipping dataset data\n",
      "Difference in array '//file_create_date' (subset):\n",
      "  Array 1: [b'2023-11-20T20:47:40.786061+00:00' b'2023-11-20T20:47:40.786061+00:00'\n",
      " b'2023-11-20T20:47:40.786061+00:00']\n",
      "  Array 2: [b'2023-02-12T21:42:50.494421+00:00' b'2023-02-12T21:42:50.494421+00:00'\n",
      " b'2023-02-12T21:42:50.494421+00:00']\n",
      "Difference in attributes in dataset '//general/subject/age'\n",
      "  attr 1: {'reference': 'birth'}\n",
      "  attr 2: {}\n",
      "Difference in dataset '//identifier':\n",
      "  File 1: b'644c4e77-0a4b-46a0-880c-22d657611aa0'\n",
      "  File 2: b'5826ca3a-35cc-43f6-b63b-24280a2ad602'\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "skipping dataset data\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation1'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 1 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 1 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation2'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 2 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 2 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation3'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 3 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 3 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation4'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 4 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 4 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation5'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 5 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 5 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation6'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 6 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 6 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation7'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 7 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 7 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in attributes in group '//processing/ophys/ImageSegmentation/PlaneSegmentation8'\n",
      "  attr 1: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 8 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-11-20. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "  attr 2: {'colnames': array(['image_mask', 'mask_type'], dtype=object), 'description': 'The output from segmenting field 8 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.', 'namespace': 'core', 'neurodata_type': 'PlaneSegmentation'}\n",
      "Difference in dataset '//session_description':\n",
      "  File 1: b'Contains calcium imaging recorded from multiple cortical visual areas and behavioral measurements while a mouse viewed natural movies and parametric stimuli. The structural ids are added as plane segmentation columns from the CAVE database on 2023-11-20. To access the latest revision see the notebook that is linked to the dandiset. The structural ids might not be present for all plane segmentations.'\n",
      "  File 2: b'Contains calcium imaging recorded from multiple cortical visual areas and behavioral measurements while a mouse viewed natural movies and parametric stimuli. The structural ids are added as plane segmentation columns from the CAVE database on 2023-02-12. To access the latest revision see the notebook that is linked to the dandiset. The structural ids might not be present for all plane segmentations.'\n",
      "Dataset '2.6.0-alpha' is missing in '//specifications/core' in second file\n",
      "Dataset '2.5.0' is missing in '//specifications/core' in first file\n",
      "Dataset '1.8.0' is missing in '//specifications/hdmf-common' in second file\n",
      "Dataset '1.5.1' is missing in '//specifications/hdmf-common' in first file\n",
      "Dataset '0.5.0' is missing in '//specifications/hdmf-experimental' in second file\n",
      "Dataset '0.2.0' is missing in '//specifications/hdmf-experimental' in first file\n"
     ]
    }
   ],
   "source": [
    "compare_nwb_files(local_file_path,dandi_file_path,excluded_datasets = set(['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956eee60-3b8f-436d-a7f1-2308d14d153c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1fda2-52f3-49b5-8dda-041192dba61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = h5py.File(local_file_path,'r')\n",
    "date1 = file1['file_create_date']\n",
    "\n",
    "file2 = h5py.File(dandi_file_path,'r')\n",
    "date2 = file2['file_create_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "01f1c09f-6b9b-4478-8d2d-b6d50ff8e332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 object reference>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs1['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e84021d-5974-4b62-87fe-57e00c6af8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pynwb\n",
      "Version: 2.5.0\n",
      "Summary: Package for working with Neurodata stored in the NWB format\n",
      "Home-page: https://github.com/NeurodataWithoutBorders/pynwb\n",
      "Author: Andrew Tritt\n",
      "Author-email: ajtritt@lbl.gov\n",
      "License: BSD\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: h5py, hdmf, numpy, pandas, python-dateutil, setuptools\n",
      "Required-by: dandi, microns-to-nwb, neuroconv, nwbinspector, roiextractors\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show pynwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e121d32-3edd-4606-b432-b994ce56f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: neuroconv\n",
      "Version: 0.2.4\n",
      "Summary: Convert data from proprietary formats to NWB format.\n",
      "Home-page: https://github.com/catalystneuro/neuroconv\n",
      "Author: Cody Baker, Szonja Weigl, Heberto Mayorquin, Luiz Tauffer, and Ben Dichter.\n",
      "Author-email: ben.dichter@catalystneuro.com\n",
      "License: UNKNOWN\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: dandi, h5py, hdmf, jsonschema, numpy, pandas, psutil, pynwb, PyYAML, scipy, tqdm\n",
      "Required-by: microns-to-nwb\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show neuroconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa93c221-9887-4820-b21f-0fc6faa89ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: roiextractors\n",
      "Version: 0.5.4\n",
      "Summary: Python module for extracting optical physiology ROIs and traces for various file types and formats\n",
      "Home-page: https://github.com/catalystneuro/roiextractors\n",
      "Author: Heberto Mayorquin, Szonja Weigl, Cody Baker, Ben Dichter, Alessio Buccino\n",
      "Author-email: ben.dichter@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: dill, h5py, lazy-ops, psutil, pynwb, PyYAML, scipy, tqdm\n",
      "Required-by: microns-to-nwb\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show roiextractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a761d1c-7ee4-48a3-a733-cf494338f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tifffile\n",
      "Version: 2023.3.21\n",
      "Summary: Read and write TIFF files\n",
      "Home-page: https://www.cgohlke.com\n",
      "Author: Christoph Gohlke\n",
      "Author-email: cgohlke@cgohlke.com\n",
      "License: BSD\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: numpy\n",
      "Required-by: microns-to-nwb\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effff23a-00d6-45b1-80e7-4ddb1d0f4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: opencv-python-headless\n",
      "Version: 4.8.1.78\n",
      "Summary: Wrapper package for OpenCV python bindings.\n",
      "Home-page: https://github.com/opencv/opencv-python\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: numpy, numpy\n",
      "Required-by: microns-to-nwb\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5edd7-f320-49ec-bdef-7fa43b4608ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "70d9b5d9-a1ee-42b9-ac24-d4115d933b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.specloc': <HDF5 object reference>,\n",
       " 'namespace': 'core',\n",
       " 'neurodata_type': 'NWBFile',\n",
       " 'nwb_version': '2.6.0'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'.specloc': <HDF5 object reference>,\n",
       " 'namespace': 'core',\n",
       " 'neurodata_type': 'NWBFile',\n",
       " 'nwb_version': '2.5.0'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs1 = {key: file1.attrs[key] for key in file1.attrs if key not in excluded_attributes}\n",
    "attrs2 = {key: file2.attrs[key] for key in file2.attrs if key not in excluded_attributes}\n",
    "display(attrs1)\n",
    "display(attrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35177cb3-eb1a-4aa4-81ff-5a9894592e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': 'birth'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs1 = {key: file1['general']['subject']['age'].attrs[key] for key in file1['general']['subject']['age'].attrs if key not in excluded_attributes}\n",
    "attrs2 = {key: file2['general']['subject']['age'].attrs[key] for key in file2['general']['subject']['age'].attrs if key not in excluded_attributes}\n",
    "display(attrs1)\n",
    "display(attrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8bdb02e5-9043-4061-a73c-c07565d98f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'all rois in field 1',\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'DynamicTableRegion',\n",
       " 'table': <HDF5 object reference>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'all rois in field 1',\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'DynamicTableRegion',\n",
       " 'table': <HDF5 object reference>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs1 = {key: file1['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois'].attrs[key] for key in file1['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois'].attrs if key not in excluded_attributes}\n",
    "attrs2 = {key: file2['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois'].attrs[key] for key in file2['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois'].attrs if key not in excluded_attributes}\n",
    "display(attrs1)\n",
    "display(attrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3b08dda5-cde2-4681-939d-eee1516923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = file1['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois']\n",
    "dataset2 = file2['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['rois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "924b86c9-eb33-430a-991a-67a9d0173d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'all rois in field 1',\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'DynamicTableRegion',\n",
       " 'table': <HDF5 object reference>}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "09895979-ef73-4f31-a639-d8ab1c16775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'all rois in field 1',\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'DynamicTableRegion',\n",
       " 'table': <HDF5 object reference>}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b0296364-e962-414e-a3ff-c654caf2295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs1.keys() == attrs2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2f9d96b6-dbbb-4f72-9279-d1f2dfd0a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([np.all(v1==v2) for v1,v2 in zip(attrs1.values(),attrs2.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7d83b130-5f4c-4244-b31d-dc1a4ce79457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in attributes in group 'temp'\n",
      "  attr 1: {'description': 'all rois in field 1', 'namespace': 'hdmf-common', 'neurodata_type': 'DynamicTableRegion', 'table': <HDF5 object reference>}\n",
      "  attr 2: {'description': 'all rois in field 1', 'namespace': 'hdmf-common', 'neurodata_type': 'DynamicTableRegion', 'table': <HDF5 object reference>}\n"
     ]
    }
   ],
   "source": [
    "if isinstance(dataset1, h5py.Dataset) and isinstance(dataset2, h5py.Dataset):\n",
    "    # Compare group attributes (excluding 'object_id')\n",
    "    attrs1 = {key: dataset1.attrs[key] for key in dataset1.attrs if key not in excluded_attributes}\n",
    "    # attrs2 = {key: dataset2.attrs[key] for key in dataset2.attrs if key != 'object_id'}\n",
    "    attrs2 = {key: dataset2.attrs[key] for key in dataset2.attrs if key not in excluded_attributes}\n",
    "\n",
    "    if not (attrs1.keys() == attrs2.keys() and np.all([np.all(v1==v2) for v1,v2 in zip(attrs1.values(),attrs2.values())])):\n",
    "    # if attrs1 != attrs2:\n",
    "        print(f\"Difference in attributes in group '{path}'\")\n",
    "        print(f\"  attr 1: {attrs1}\")\n",
    "        print(f\"  attr 2: {attrs2}\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"No difference in attributes in group '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2dff4d3f-4ca1-408d-bcb2-9e08f888ac4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc7b3a6b-1b5d-48f6-b2ad-9ed4dcabe981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c30b1bf0-9da3-4c8c-81bb-a3ca4dbd192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d416e74-856d-4ab2-b3d9-3654c510011b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac1d68-d65e-4883-bb23-3f2b8a96cbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4379c1-cae2-4b0a-8c27-d3fe94018143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86085082-e34b-46d0-b7ac-56408b4c1ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ffeadbc7-21f0-4cdc-8810-ac34a669f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = list(attrs1.values())[-1]\n",
    "v2 = list(attrs2.values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "eed31796-39b7-4a51-8a75-59f94691495c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/processing/ophys/ImageSegmentation/PlaneSegmentation1'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1[v1].name == file2[v2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "36bcfc7a-c5c6-4981-9356-a534c28f34d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'typecode',\n",
       " 'typesize']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10dbcac0-611b-4571-8c2b-9cc7beee234c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 object reference>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91364f15-b9c1-4e25-abdb-9d801075a8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h5py.h5r.Reference"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "41815296-2d55-4fef-9530-08ee01a78184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(v2,h5py.h5r.Reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dfe9b8f1-bdab-4658-88d8-648d759568dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['all rois in field 1', 'hdmf-common', 'DynamicTableRegion', <HDF5 object reference>])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs1.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67366c09-ca79-4748-94c0-3a4751e12f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "25522c30-71cd-4822-8c92-8cd6cdac11e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"rois\": shape (643,), type \"<i8\">"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1[v1].name == file2[v2].name if np.all((v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45598d-0479-4041-89d2-10b2d65167ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b2588-ac19-4a9d-b3a0-9716325d7227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416a8d5-5f04-4d3e-a327-b750489c91b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "92b5ee18-6ab3-4f15-8e7a-29a2ff2793bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1[attrs1['table']].name == file2[attrs2['table']].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "db53df9a-8dd4-4a92-972f-711b1fb2c6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_MutableMapping__marker',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_d',\n",
       " '_e',\n",
       " '_gcpl_crt_order',\n",
       " '_id',\n",
       " '_ipython_key_completions_',\n",
       " '_lapl',\n",
       " '_lcpl',\n",
       " 'attrs',\n",
       " 'build_virtual_dataset',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'create_dataset',\n",
       " 'create_dataset_like',\n",
       " 'create_group',\n",
       " 'create_virtual_dataset',\n",
       " 'file',\n",
       " 'get',\n",
       " 'id',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'move',\n",
       " 'name',\n",
       " 'parent',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'ref',\n",
       " 'regionref',\n",
       " 'require_dataset',\n",
       " 'require_group',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values',\n",
       " 'visit',\n",
       " 'visititems']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(file1[attrs1['table']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b3a7d76e-27a3-4148-b714-62bcdee0c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/processing/ophys/ImageSegmentation/PlaneSegmentation1\" (5 members)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/processing/ophys/ImageSegmentation/PlaneSegmentation1\" (5 members)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(file1[attrs1['table']])\n",
    "display(file2[attrs2['table']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d84ac3-638e-472e-a153-283383a8a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_object_references_equal(file1, ref1, file2, ref2):\n",
    "    # Get the objects pointed to by the references\n",
    "    obj1 = file1[ref1]\n",
    "    obj2 = file2[ref2]\n",
    "\n",
    "    # Compare the paths of the objects\n",
    "    path1 = file1.get(obj1.name, None)\n",
    "    path2 = file2.get(obj2.name, None)\n",
    "\n",
    "    return path1 == path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "04191144-2b9f-44d4-a0be-fcbf4ea5bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorescence_traces1 = file1['processing']['ophys']['Fluorescence']['RoiResponseSeries1']['data'][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1af5bb29-b654-4827-87b6-22309040a629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 643)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(fluorescence_traces1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c8190b4c-a4b7-4d27-8531-ceba637d1171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1408, 1409, 1410])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_table1 = file1['processing']['ophys']['Fluorescence']['RoiResponseSeries6']['rois'][()]\n",
    "roi_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b822c7a0-3e02-44ab-b8c8-b740ddec99ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colnames': array(['image_mask', 'mask_type'], dtype=object),\n",
       " 'description': 'The output from segmenting field 1 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-12-04. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.',\n",
       " 'namespace': 'core',\n",
       " 'neurodata_type': 'PlaneSegmentation'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'colnames': array(['image_mask', 'mask_type'], dtype=object),\n",
       " 'description': 'The output from segmenting field 1 contains the image masks (weights and mask classification) and the structural ids extracted from the CAVE database on 2023-02-12. To access the latest revision from the live resource see the notebook that is linked to the dandiset. The structual ids might not exist for all plane segmentations.',\n",
       " 'namespace': 'core',\n",
       " 'neurodata_type': 'PlaneSegmentation'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs1 = {key: file1['processing']['ophys']['ImageSegmentation']['PlaneSegmentation1'].attrs[key] for key in file1['processing']['ophys']['ImageSegmentation']['PlaneSegmentation1'].attrs if key not in excluded_attributes}\n",
    "attrs2 = {key: file2['processing']['ophys']['ImageSegmentation']['PlaneSegmentation1'].attrs[key] for key in file2['processing']['ophys']['ImageSegmentation']['PlaneSegmentation1'].attrs if key not in excluded_attributes}\n",
    "display(attrs1)\n",
    "display(attrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86f418db-0bcc-4ee2-9844-1963269a8d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Index for VectorData 'cave_ids'\",\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'VectorIndex',\n",
       " 'target': <HDF5 object reference>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'description': \"Index for VectorData 'cave_ids'\",\n",
       " 'namespace': 'hdmf-common',\n",
       " 'neurodata_type': 'VectorIndex',\n",
       " 'target': <HDF5 object reference>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs1 = {key: file1['processing']['ophys']['ImageSegmentation']['PlaneSegmentation2']['cave_ids_index'].attrs[key] for key in file1['processing']['ophys']['ImageSegmentation']['PlaneSegmentation2']['cave_ids_index'].attrs if key not in excluded_attributes}\n",
    "attrs2 = {key: file2['processing']['ophys']['ImageSegmentation']['PlaneSegmentation2']['cave_ids_index'].attrs[key] for key in file2['processing']['ophys']['ImageSegmentation']['PlaneSegmentation2']['cave_ids_index'].attrs if key not in excluded_attributes}\n",
    "display(attrs1)\n",
    "display(attrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a21851-0b9a-41fe-b5cf-454f982c6c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67677dc8-69f1-4b13-851d-1e23b26bff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58872a-915a-4580-bc41-cc4792f92fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optional argument to skip testing large arrays\n",
    "# TODO add verbose option and/or logging\n",
    "# TODO find a way to build the files with NWB_version 2.5.0 instead of 2.6.0\n",
    "# TODO find a way to build with hdmf-common version 1.5.1 instead of 1.8.0\n",
    "# TODO find a way to build with hdmf-experimental version 0.2.0 instead of 0.5.0\n",
    "# TODO print only the part of the attributes that is different, not the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "92bba231-cd4e-4d05-857f-f91c3bc3745e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07223d71-02e7-4409-8197-3ae16bff0fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(imaging_rate1[()]) and np.isnan(imaging_rate2[()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4df97b2-b75c-49ed-80ef-8e85fc02a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = imaging_rate1[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba0555d3-336b-4954-a649-e468ea073997",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = imaging_rate2[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6802401-db06-4b38-81fe-6236a39823a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1==arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fb65e8c-2487-4452-bc95-7ae61d7b8d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(arr1) & np.isnan(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccddfbb1-e0d4-4be5-91a1-47b884533b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2669281f-9fa8-438a-99b5-b4d23b345596",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([1, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e81a58cf-3b85-4b10-bdd9-d03cbd43f9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((arr1 == arr2) | (np.isnan(arr1) & np.isnan(arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0694e18b-8e8c-48dc-90dc-4f0fb86b0a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((arr1 == arr2) | (np.isnan(arr1) & np.isnan(arr2))).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b15f4b36-7606-4bf3-a21f-5e9e73ec60d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1['file_create_date'][:].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3515c0dd-b25e-4d4e-964e-540903457786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1['acquisition']['EyeTracking']['eye_position']['data'][:].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51e7f572-b6d9-4dca-beb1-1b9df54c6792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1['acquisition']['EyeTracking']['eye_position']['reference_frame'][()] == file2['acquisition']['EyeTracking']['eye_position']['reference_frame'][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "761832fd-00ac-447d-b221-6acf3a137409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = file1['acquisition']['EyeTracking']['eye_position']['reference_frame']\n",
    "dataset2 = file2['acquisition']['EyeTracking']['eye_position']['reference_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d191cb7d-31d5-43ed-ab63-87eb1bd02b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'unknown'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2['acquisition']['EyeTracking']['eye_position']['reference_frame'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ea168f1-7f03-4ec2-8d62-3187fea75158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"reference_frame\": shape (), type \"|O\">"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1['acquisition']['EyeTracking']['eye_position']['reference_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd8591f9-0cc7-4371-8a25-5cb5e41b5703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f8')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1['acquisition']['TwoPhotonSeries1']['imaging_plane']['imaging_rate'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc767c-1640-4ec3-aa88-8e32bcb7ce5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7fe71-f6bc-4079-8a99-b5e474fcad1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecf731-fcd4-4dbf-af3b-740070611dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fa405-ba5a-4d5f-852c-26298642bddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bddcd-8a6f-4fec-b2a5-5394d9e2b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes differ in group '/'\n",
    "# Shapes differ in dataset '//acquisition/Video: stimulus_17797_4_9_v4/timestamps': (334501,) vs (334509,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
